{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from util.file_helper import get_readme_with_repo_name\n",
    "from util.readme_parser import ReadmeSectionParser\n",
    "from e2e_system.reproder import ClassificationReproder, _ground_truth\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"header\", \"parent_header\", \"content\"]\n",
    "model = \"bert_base_uncased\"\n",
    "model_paths = glob.glob(f\"model/{model}/**\")\n",
    "neurips_df = pd.read_csv(\n",
    "    'data/paperswithcode/neurips_checklist_manuel-100.csv')\n",
    "neurips_df[\"score\"] = neurips_df.select_dtypes(bool).sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reproder, m_df, group_by_parent, consecutive):\n",
    "    df = m_df.copy()\n",
    "    for repo in (pbar := tqdm(neurips_df.url.values, desc=\"Evaluating\")):\n",
    "        pbar.set_postfix_str(f\"Evaluating {repo}\")\n",
    "\n",
    "        readme = get_readme_with_repo_name(\"neurips\", repo)\n",
    "        readme_parser = ReadmeSectionParser(repo, readme)\n",
    "        sections = readme_parser.parse_sections(\n",
    "            group_by_parent=group_by_parent)\n",
    "        # labels = reproder.classify_sections(sections)\n",
    "        # checklist, scores, _, _ = reproder.checklist(labels)\n",
    "        # record = df[df[\"url\"] == repo]\n",
    "        # if consecutive:\n",
    "        #     labels = reproder.merge_consecutive(pd.DataFrame(labels))\n",
    "\n",
    "        # reprod_score = reproder.calculate_reproducibility(\n",
    "        #     pd.DataFrame(labels), coeff=0.16, punishment=False)\n",
    "        # df.loc[record.index,\n",
    "        #        \"true_reprod_score\"] = df.loc[record.index, \"score\"] * 0.16\n",
    "        # df.loc[record.index, \"reprod_score\"] = reprod_score\n",
    "        # for k, v in checklist.items():\n",
    "        #     df.loc[record.index, f\"{k}_pred\"] = v\n",
    "        #     df.loc[record.index, f\"{k}_score\"] = scores[k] if v else 0\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1332ebca99b4c70b6ae3073beda12eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c062fa72892f4780b0ed0b61ad57575a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262c7562d40d4e8f8a5982b08e7980ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51cf5e2166b94b5196ddc97059098b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d3aa0affea4669be4fba961d7a10a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m (pbar \u001b[39m:=\u001b[39m tqdm(model_paths)):\n\u001b[0;32m      2\u001b[0m     pbar\u001b[39m.\u001b[39mset_postfix_str(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEvaluating \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     reproder \u001b[39m=\u001b[39m ClassificationReproder(model, keys)\n\u001b[0;32m      4\u001b[0m     base_ev \u001b[39m=\u001b[39m evaluate(reproder, neurips_df,\n\u001b[0;32m      5\u001b[0m                        group_by_parent\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, consecutive\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m     grouped_ev \u001b[39m=\u001b[39m evaluate(reproder, neurips_df,\n\u001b[0;32m      7\u001b[0m                           group_by_parent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, consecutive\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Thesis\\reproducibility_assessment\\src\\e2e_system\\reproder.py:108\u001b[0m, in \u001b[0;36mClassificationReproder.__init__\u001b[1;34m(self, model_path, keys)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, model_path: \u001b[39mstr\u001b[39m, keys: \u001b[39mlist\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 108\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(model_path, keys)\n",
      "File \u001b[1;32md:\\Thesis\\reproducibility_assessment\\src\\e2e_system\\reproder.py:33\u001b[0m, in \u001b[0;36mReproderBase.__init__\u001b[1;34m(self, model_path, keys)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeys \u001b[39m=\u001b[39m keys\n\u001b[0;32m     32\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_model(model_path)\n",
      "File \u001b[1;32md:\\Thesis\\reproducibility_assessment\\src\\e2e_system\\reproder.py:111\u001b[0m, in \u001b[0;36mClassificationReproder.init_model\u001b[1;34m(self, model_path)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minit_model\u001b[39m(\u001b[39mself\u001b[39m, model_path: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m pipeline(\n\u001b[0;32m    112\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mtext-classification\u001b[39;49m\u001b[39m\"\u001b[39;49m, model\u001b[39m=\u001b[39;49mmodel_path, truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, device\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m \u001b[39mif\u001b[39;49;00m torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mis_available() \u001b[39melse\u001b[39;49;00m \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, use_auth_token\u001b[39m=\u001b[39;49mAUTH_TOKEN)\n",
      "File \u001b[1;32md:\\Thesis\\reproducibility_assessment\\src\\.venv\\lib\\site-packages\\transformers\\pipelines\\__init__.py:979\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m device\n\u001b[1;32m--> 979\u001b[0m \u001b[39mreturn\u001b[39;00m pipeline_class(model\u001b[39m=\u001b[39mmodel, framework\u001b[39m=\u001b[39mframework, task\u001b[39m=\u001b[39mtask, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Thesis\\reproducibility_assessment\\src\\.venv\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:83\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 83\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     85\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_model_type(\n\u001b[0;32m     86\u001b[0m         TF_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING\n\u001b[0;32m     87\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     88\u001b[0m         \u001b[39melse\u001b[39;00m MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING\n\u001b[0;32m     89\u001b[0m     )\n",
      "File \u001b[1;32md:\\Thesis\\reproducibility_assessment\\src\\.venv\\lib\\site-packages\\transformers\\pipelines\\base.py:773\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[1;34m(self, model, tokenizer, feature_extractor, image_processor, modelcard, framework, task, args_parser, device, torch_dtype, binary_output, **kwargs)\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m=\u001b[39m framework\n\u001b[0;32m    772\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m device \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(device, \u001b[39mint\u001b[39m) \u001b[39mand\u001b[39;00m device \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m--> 773\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m    775\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    776\u001b[0m     \u001b[39m# `accelerate` device map\u001b[39;00m\n\u001b[0;32m    777\u001b[0m     hf_device_map \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39m\"\u001b[39m\u001b[39mhf_device_map\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Thesis\\reproducibility_assessment\\src\\.venv\\lib\\site-packages\\transformers\\modeling_utils.py:1896\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1891\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1892\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`.to` is not supported for `8-bit` models. Please use the model as it is, since the\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1893\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m model has already been set to the correct devices and casted to the correct `dtype`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1894\u001b[0m     )\n\u001b[0;32m   1895\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1896\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mto(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Thesis\\reproducibility_assessment\\src\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[1;32md:\\Thesis\\reproducibility_assessment\\src\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Thesis\\reproducibility_assessment\\src\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: Module._apply at line 797 (3 times)]\u001b[0m\n",
      "File \u001b[1;32md:\\Thesis\\reproducibility_assessment\\src\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Thesis\\reproducibility_assessment\\src\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32md:\\Thesis\\reproducibility_assessment\\src\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for model in (pbar := tqdm(model_paths)):\n",
    "    pbar.set_postfix_str(f\"Evaluating {model}\")\n",
    "    reproder = ClassificationReproder(model, keys)\n",
    "    base_ev = evaluate(reproder, neurips_df,\n",
    "                       group_by_parent=False, consecutive=False)\n",
    "    grouped_ev = evaluate(reproder, neurips_df,\n",
    "                          group_by_parent=True, consecutive=False)\n",
    "    consecutive_ev = evaluate(reproder, neurips_df,\n",
    "                              group_by_parent=False, consecutive=True)\n",
    "    grouped_consecutive_ev = evaluate(\n",
    "        reproder, neurips_df, group_by_parent=True, consecutive=True)\n",
    "\n",
    "    # save_main_dir = f'data/paperswithcode/evaluated/classification/{model}/'\n",
    "    # save_dir = os.path.join(save_main_dir, model.split(\"\\\\\")[-1])\n",
    "    # shutil.rmtree(save_dir, ignore_errors=True)\n",
    "    # os.makedirs(save_dir, exist_ok=True)\n",
    "    # info = {\n",
    "    #     \"model_dir\": model,\n",
    "    #     \"keys\": keys,\n",
    "    #     \"time\": datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # }\n",
    "    # open(os.path.join(save_dir, \"info.json\"), 'w').write(\n",
    "    #     json.dumps(info, indent=4))\n",
    "\n",
    "    # base_ev.to_csv(f'{save_dir}/neurips_base.csv', index=False)\n",
    "    # grouped_ev.to_csv(f'{save_dir}/neurips_grouped.csv', index=False)\n",
    "    # consecutive_ev.to_csv(\n",
    "    #     f'{save_dir}/neurips_consecutive.csv', index=False)\n",
    "    # grouped_consecutive_ev.to_csv(\n",
    "    #     f'{save_dir}/neurips_grouped_consecutive.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
