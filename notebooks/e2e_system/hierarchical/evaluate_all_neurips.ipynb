{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from util.readme_parser import ReadmeSectionParser\n",
    "from e2e_system.reproder import HierarchicalReproder, _ground_truth\n",
    "\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import glob\n",
    "from util.file_helper import get_readme_with_repo_name\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"header\", \"parent_header\", \"content\"]\n",
    "model = \"hierarchical\"\n",
    "model_paths = glob.glob(f\"model/{model}/**\")\n",
    "neurips_df = pd.read_csv(\n",
    "    'data/paperswithcode/neurips_checklist_manuel-100.csv')\n",
    "neurips_df[\"score\"] = neurips_df.select_dtypes(bool).sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reproder: HierarchicalReproder, m_df, type=1):\n",
    "    df = m_df.copy()\n",
    "    for repo in (pbar := tqdm(neurips_df.url.values, desc=\"Evaluating\")):\n",
    "        pbar.set_postfix_str(f\"Evaluating {repo}\")\n",
    "        readme = get_readme_with_repo_name(\"neurips\", repo)\n",
    "        sections = ReadmeSectionParser(\n",
    "            repo, readme).parse_sections(group_by_parent=False)\n",
    "        record = df[df[\"url\"] == repo]\n",
    "        if len(sections) == 0:\n",
    "            df.loc[record.index, \"reprod_score\"] = 0\n",
    "            continue\n",
    "        readme_text = ReadmeSectionParser.merge_sections(\n",
    "            pd.DataFrame(sections), with_newline=True, keys=keys)\n",
    "        logits = reproder.evaluate(readme_text)\n",
    "        reprod_score = reproder.calculate_reproducibility(logits, type=type)\n",
    "        record = df[df[\"url\"] == repo]\n",
    "        df.loc[record.index, \"reprod_score\"] = reprod_score\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in (pbar := tqdm(model_paths)):\n",
    "    pbar.set_postfix_str(f\"Evaluating {model}\")\n",
    "    reproder = HierarchicalReproder(model, keys)\n",
    "    direct_classification = evaluate(reproder, neurips_df, type=1)\n",
    "    weighted_score = evaluate(reproder, neurips_df, type=2)\n",
    "    direct_coeff = evaluate(reproder, neurips_df, type=3)\n",
    "\n",
    "    save_main_dir = f'data/paperswithcode/evaluated/hierarchical/{model}/'\n",
    "    save_dir = os.path.join(save_main_dir, model.split(\"\\\\\")[-1])\n",
    "    shutil.rmtree(save_dir, ignore_errors=True)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    info = {\n",
    "        \"model_dir\": model,\n",
    "        \"keys\": keys,\n",
    "        \"time\": datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    }\n",
    "    # open(os.path.join(save_dir, \"info.json\"), 'w').write(\n",
    "    #     json.dumps(info, indent=4))\n",
    "\n",
    "    # direct_classification.to_csv(\n",
    "    #     f'{save_dir}/direct_classification.csv', index=False)\n",
    "    # weighted_score.to_csv(\n",
    "    #     f'{save_dir}/weighted_score.csv', index=False)\n",
    "    # direct_coeff.to_csv(\n",
    "    #     f'{save_dir}/direct_coeff.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
